{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T15:12:24.363552Z",
     "start_time": "2025-07-18T15:12:08.405898Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from paths import DATA_FOLDER, PROCESSED_DATA_FOLDER, MODELS_FOLDER, ML_FOLDER\n",
    "\n",
    "from chromadb.errors import UniqueConstraintError\n",
    "from importlib_metadata import metadata\n",
    "from torch.cuda import device\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import chromadb\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_FOLDER = DATA_FOLDER\n",
    "PROCESSED_DATA_FOLDER = PROCESSED_DATA_FOLDER\n",
    "MODELS_FOLDER = MODELS_FOLDER\n",
    "ML_FOLDER = ML_FOLDER\n",
    "MODEL_ID = \"BAAI/bge-m3\""
   ],
   "id": "398186b6e63d129e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "b511a18fe92cf520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## We recommend to use the following pipeline: hybrid retrieval + re-ranking.\n",
    "\n",
    "- [ ] Hybrid retrieval leverages the strengths of various methods, offering higher accuracy and stronger generalization capabilities. A classic example: using both embedding retrieval and the BM25 algorithm. Now, you can try to use BGE-M3, which supports both embedding and sparse retrieval. This allows you to obtain token weights (similar to the BM25) without any additional cost when generate dense embeddings. To use hybrid retrieval, you can refer to Vespa and Milvus.\n",
    "\n",
    "- [ ] As cross-encoder models, re-ranker demonstrates higher accuracy than bi-encoder embedding model. Utilizing the re-ranking model (e.g., bge-reranker, bge-reranker-v2) after retrieval can further filter the selected text."
   ],
   "id": "c8fe56400e899a63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = SentenceTransformer(MODEL_ID)\n",
    "model = SentenceTransformer(f'{ML_FOLDER}/BGE-m3')"
   ],
   "id": "dc2b2753d3f7ba21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SentenceTransformerEmbeddingFunction:\n",
    "    def __init__(self, model_name_or_path):\n",
    "        self.model_name = model_name_or_path\n",
    "        self.model = SentenceTransformer(model_name_or_path)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        embeddings = self.model.encode(input, normalize_embeddings=True, device='cuda:0')\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def name(self):\n",
    "        return self.model_name"
   ],
   "id": "51d87fcf731e71be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model.save(f'{ML_FOLDER}/BGE-m3')",
   "id": "2f1eafbe12de748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# embedding_func = SentenceTransformerEmbeddingFunction(MODEL_ID)\n",
    "embedding_func = SentenceTransformerEmbeddingFunction(f'{ML_FOLDER}/BGE-m3')"
   ],
   "id": "be8ff5d3668121a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_vectors_v2 = []\n",
    "for file in os.listdir(f'{PROCESSED_DATA_FOLDER}/classes'):\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/classes/{file}', 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        results = embedding_func(line)\n",
    "        class_vectors_v2.append(results)"
   ],
   "id": "5ab0f3b5dce4184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_vectors_v3 = pd.DataFrame(class_vectors_v2)\n",
    "class_vectors_v3"
   ],
   "id": "1d7bb6eaf4236be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainig_vectors_v1 = []\n",
    "for file in os.listdir(f'{PROCESSED_DATA_FOLDER}/training'):\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/training/{file}', 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        results = embedding_func(line)\n",
    "        trainig_vectors_v1.append(results)"
   ],
   "id": "5a11be86109d5008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chrome_persistent_client = chromadb.PersistentClient(path=f'{DATA_FOLDER}/chromadb')",
   "id": "e1e8bb06923005a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# chrome_persistent_client.list_collections()",
   "id": "c0acdb72f9616401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# chrome_persistent_client.delete_collection('my_rag_v1')",
   "id": "7cf5d2af75eeda02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "collection = chrome_persistent_client.get_or_create_collection(name='my_rag_v1', embedding_function=embedding_func)",
   "id": "f2052410e77be5ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "metadatas =()\n",
    "ids = []\n",
    "embeddings = []\n",
    "\n",
    "class_folder = os.listdir(f'{PROCESSED_DATA_FOLDER}/classes')\n",
    "training_folder = os.listdir(f'{PROCESSED_DATA_FOLDER}/training')"
   ],
   "id": "3d0295ccb6292f0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for file in class_folder:\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/classes/{file}', 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read())\n",
    "\n",
    "for file in training_folder:\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/training/{file}', 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read())"
   ],
   "id": "e22bd89e04228a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metadatas = (\n",
    "    [{'category': 'classes'} for _ in class_folder] +\n",
    "    [{'category': 'code + explanation'} for _ in training_folder]\n",
    ")"
   ],
   "id": "f0a8c0b2d222e972",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ids = [f'id{i}' for i in range(1, len(class_folder) + len(training_folder) + 1)]",
   "id": "f2afc9ef537825b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings.extend(class_vectors_v2)\n",
    "embeddings.extend(trainig_vectors_v1)"
   ],
   "id": "88f9ffc995559cb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "collection.upsert(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,\n",
    ")"
   ],
   "id": "92aaec02eaa33522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e9be391a79ab41c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = collection.query(\n",
    "    query_texts=['Write a codefor insurance with the document 207'],\n",
    "    n_results=7,\n",
    ")\n",
    "result"
   ],
   "id": "4faeb872d29570ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "81f463073b40fa27",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
