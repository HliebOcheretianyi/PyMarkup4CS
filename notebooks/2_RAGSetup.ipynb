{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from paths import DATA_FOLDER, PROCESSED_DATA_FOLDER, MODELS_FOLDER, ML_FOLDER\n",
    "from BasicClasses import *\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import chromadb\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_FOLDER = DATA_FOLDER\n",
    "PROCESSED_DATA_FOLDER = PROCESSED_DATA_FOLDER\n",
    "MODELS_FOLDER = MODELS_FOLDER\n",
    "ML_FOLDER = ML_FOLDER\n",
    "MODEL_ID = \"BAAI/bge-m3\""
   ],
   "id": "398186b6e63d129e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "b511a18fe92cf520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## We recommend to use the following pipeline: hybrid retrieval + re-ranking.\n",
    "\n",
    "- [ ] Hybrid retrieval leverages the strengths of various methods, offering higher accuracy and stronger generalization capabilities. A classic example: using both embedding retrieval and the BM25 algorithm. Now, you can try to use BGE-M3, which supports both embedding and sparse retrieval. This allows you to obtain token weights (similar to the BM25) without any additional cost when generate dense embeddings. To use hybrid retrieval, you can refer to Vespa and Milvus.\n",
    "\n",
    "- [ ] As cross-encoder models, re-ranker demonstrates higher accuracy than bi-encoder embedding model. Utilizing the re-ranking model (e.g., bge-reranker, bge-reranker-v2) after retrieval can further filter the selected text."
   ],
   "id": "c8fe56400e899a63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = SentenceTransformer(MODEL_ID)\n",
    "model = SentenceTransformer(f'{ML_FOLDER}/BGE-m3')"
   ],
   "id": "dc2b2753d3f7ba21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model.save(f'{ML_FOLDER}/BGE-m3')",
   "id": "2f1eafbe12de748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# embedding_func = SentenceTransformerEmbeddingFunction(MODEL_ID)\n",
    "embedding_func = SentenceTransformerEmbeddingFunction(f'{ML_FOLDER}/BGE-m3')"
   ],
   "id": "be8ff5d3668121a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_vectors_v2 = []\n",
    "for file in os.listdir(f'{PROCESSED_DATA_FOLDER}/classes'):\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/classes/{file}', 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        results = embedding_func(line)\n",
    "        class_vectors_v2.append(results)"
   ],
   "id": "5ab0f3b5dce4184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_vectors_v3 = pd.DataFrame(class_vectors_v2)\n",
    "class_vectors_v3"
   ],
   "id": "1d7bb6eaf4236be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainig_vectors_v1 = []\n",
    "for file in os.listdir(f'{PROCESSED_DATA_FOLDER}/training'):\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/training/{file}', 'r', encoding='utf-8') as f:\n",
    "        line = f.read()\n",
    "        results = embedding_func(line)\n",
    "        trainig_vectors_v1.append(results)"
   ],
   "id": "5a11be86109d5008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chrome_persistent_client = chromadb.PersistentClient(path=f'{DATA_FOLDER}/chromadb')",
   "id": "e1e8bb06923005a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chrome_persistent_client.list_collections()",
   "id": "c0acdb72f9616401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# chrome_persistent_client.delete_collection('my_rag_v1')",
   "id": "7cf5d2af75eeda02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "collection = chrome_persistent_client.get_or_create_collection(name='my_rag_v1', embedding_function=embedding_func)",
   "id": "f2052410e77be5ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "metadatas =()\n",
    "ids = []\n",
    "embeddings = []\n",
    "\n",
    "class_folder = os.listdir(f'{PROCESSED_DATA_FOLDER}/classes')\n",
    "training_folder = os.listdir(f'{PROCESSED_DATA_FOLDER}/training')"
   ],
   "id": "3d0295ccb6292f0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for file in class_folder:\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/classes/{file}', 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read())\n",
    "\n",
    "for file in training_folder:\n",
    "    with open(f'{PROCESSED_DATA_FOLDER}/training/{file}', 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read())"
   ],
   "id": "e22bd89e04228a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metadatas = (\n",
    "    [{'category': 'classes'} for _ in class_folder] +\n",
    "    [{'category': 'code + explanation'} for _ in training_folder]\n",
    ")"
   ],
   "id": "f0a8c0b2d222e972",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ids = [f'id{i}' for i in range(1, len(class_folder) + len(training_folder) + 1)]",
   "id": "f2afc9ef537825b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings.extend(class_vectors_v2)\n",
    "embeddings.extend(trainig_vectors_v1)"
   ],
   "id": "88f9ffc995559cb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "collection.upsert(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,\n",
    ")"
   ],
   "id": "92aaec02eaa33522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = collection.query(\n",
    "    query_texts=['Write a codefor insurance with the document 207'],\n",
    "    n_results=7,\n",
    ")\n",
    "result"
   ],
   "id": "4faeb872d29570ea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
