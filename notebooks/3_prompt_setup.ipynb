{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T20:33:38.949181Z",
     "start_time": "2025-07-13T20:33:38.919174Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from paths import DATA_FOLDER, PROCESSED_DATA_FOLDER, MODELS_FOLDER, ML_FOLDER\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import cached_file, WEIGHTS_NAME\n",
    "from transformers.utils import TRANSFORMERS_CACHE\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T19:45:34.913095Z",
     "start_time": "2025-07-13T19:45:34.885871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_FOLDER = DATA_FOLDER\n",
    "PROCESSED_DATA_FOLDER = PROCESSED_DATA_FOLDER\n",
    "MODELS_FOLDER = MODELS_FOLDER\n",
    "ML_FOLDER = ML_FOLDER\n",
    "MODEL_ID = \"BAAI/bge-m3\""
   ],
   "id": "2172f5b73b5c986",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T19:45:34.958782Z",
     "start_time": "2025-07-13T19:45:34.945098Z"
    }
   },
   "cell_type": "code",
   "source": "CODE_MODEL_ID = \"Qwen/Qwen3-0.6B\"",
   "id": "96c5721038195aef",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T19:45:53.282363Z",
     "start_time": "2025-07-13T19:45:34.965785Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForCausalLM.from_pretrained(CODE_MODEL_ID)",
   "id": "e05c810677a44202",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cda9fa3292f44c0a0b4aaf494791577"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e73addaabdb42b99a986f50473d8d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a8d6be445974fd4b8760ad9b377f842"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:02:11.010883Z",
     "start_time": "2025-07-13T21:02:09.238284Z"
    }
   },
   "cell_type": "code",
   "source": "model.save_pretrained(f'{ML_FOLDER}/Qwen3-0.6B')",
   "id": "c1a593a050b67b6a",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T19:45:59.480510Z",
     "start_time": "2025-07-13T19:45:59.475508Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Default cache dir: {AutoModelForCausalLM.from_pretrained.__defaults__}\")",
   "id": "d5df3928e0afb268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default cache dir: None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T19:46:05.259228Z",
     "start_time": "2025-07-13T19:46:05.248225Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Transformers is using cache: {TRANSFORMERS_CACHE}\")",
   "id": "5d660bf9742556e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers is using cache: D:\\ML\\HFcache\\hub\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T20:33:41.184254Z",
     "start_time": "2025-07-13T20:33:41.162251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a senior C# programmer that writes code based on the provided context.\n",
    "\n",
    "    Instructions:\n",
    "    - Read the provided context carefully\n",
    "    - If multiple documents are provided, synthesize information from all relevant sources\n",
    "    - Use only the information provided in the context\n",
    "    - If the context doesn't contain enough information, say so and then try to write what you can\n",
    "    - Be accurate and cite specific parts of the context when possible\n",
    "    - Follow C# best practices and naming conventions\n",
    "    - Include necessary using statements\n",
    "    - Add brief comments for complex logic\n",
    "\n",
    "    Response format:\n",
    "    - Write at the start (AS A COMMENT) your confidence level (High/Medium/Low)\n",
    "    - Plain code which can be straightforward pasted to the code editor\n",
    "    - No markdown formatting, just plain C# code\n",
    "    \"\"\"),\n",
    "    (\"human\", \"\"\"Context: {context}\n",
    "\n",
    "    Request: {question}\n",
    "\n",
    "    Please provide a comprehensive answer following the instructions above.\n",
    "\n",
    "    Answer:\"\"\")\n",
    "])"
   ],
   "id": "ce40338b09a6583e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T20:49:41.828740Z",
     "start_time": "2025-07-13T20:49:41.816736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_rag_chain(retriever, llm, prompt_template):\n",
    "    \"\"\"Create a RAG chain with retriever, LLM, and prompt\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def format_docs(result):\n",
    "        \"\"\"Format retrieved documents for the prompt\"\"\"\n",
    "\n",
    "        documents = result['documents'][0]\n",
    "        metadatas = result['metadatas'][0]\n",
    "        distances = result['distances'][0]\n",
    "        ids = result['ids'][0]\n",
    "\n",
    "        context_for_llm = []\n",
    "        for i, (doc, metadata, distance, doc_id) in enumerate(zip(documents, metadatas, distances, ids)):\n",
    "            context_for_llm.append({\n",
    "                'rank': i + 1,\n",
    "                'content': doc,\n",
    "                'category': metadata['category'],\n",
    "                'id': doc_id,\n",
    "                'similarity_score': distance\n",
    "            })\n",
    "\n",
    "            formatted_context = \"\"\n",
    "            for item in context_for_llm:\n",
    "                formatted_context += f\"\"\"\n",
    "                --- Document {item['rank']} (ID: {item['id']}) ---\n",
    "                Category: {item['category']}\n",
    "                Similarity Score: {item['similarity_score']:.4f}\n",
    "                Content:\n",
    "                {item['content']}\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        return formatted_context.strip()\n",
    "\n",
    "    # Create the chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "\n"
   ],
   "id": "ac6a18839b66f5c7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomChromaRetriever:\n",
    "    \"\"\"Custom retriever for ChromaDB with enhanced functionality\"\"\"\n",
    "\n",
    "    def __init__(self, collection, k=10):\n",
    "        self.collection = collection\n",
    "        self.k = k\n",
    "\n",
    "    def invoke(self, query):\n",
    "        \"\"\"Retrieve documents for a given query\"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=self.k\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        \"\"\"Alternative method for compatibility\"\"\"\n",
    "        return self.invoke(query)"
   ],
   "id": "c863484c0ce27cdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# retriever = CustomChromaRetriever(collection, k=3)"
   ],
   "id": "53e3b5c6045fd078"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
